{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccfcd580",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "载入需要用到的包和数据\n",
    "\"\"\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6cf92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17e255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "with open(\"./DataSets/shakespeare.txt\", 'r') as file:\n",
    "    data = file.read()\n",
    "print(data[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8430dabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 1115394 characters, and 65 unique ones.\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('Data has %d characters, and %d unique ones.' % (data_size, vocab_size))\n",
    "char_to_index = {ch:i for i, ch in enumerate(chars)}\n",
    "index_to_char = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "111da90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 0,\n",
       " 'T': 1,\n",
       " 'b': 2,\n",
       " 'p': 3,\n",
       " 'q': 4,\n",
       " 'm': 5,\n",
       " 'V': 6,\n",
       " 'J': 7,\n",
       " 'O': 8,\n",
       " 'Z': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(char_to_index.items()))\n",
    "dict(list(char_to_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527b5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "参数初始化\n",
    "w_ih: 从输入层到隐藏层的权重矩阵\n",
    "w_hh: 从隐藏层到隐藏层的权重矩阵\n",
    "w_ho: 从隐藏层到输出层的权重矩阵\n",
    "b_hh: 从隐藏层到隐藏层的横截距\n",
    "b_ho: 从隐藏层到输出层的横截距\n",
    "\"\"\"\n",
    "\n",
    "hidden_size = 20\n",
    "w_ih = np.random.randn(vocab_size, hidden_size)*0.01\n",
    "w_hh = np.random.randn(hidden_size, hidden_size)*0.01\n",
    "w_ho = np.random.randn(hidden_size, vocab_size)*0.01\n",
    "b_hh = np.zeros((1, hidden_size))\n",
    "b_ho = np.zeros((1, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50b8a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "inputs, targets: 输入数据，目标数据，都是整数序列（字符编码）\n",
    "prev_hidden: 隐藏层初始值\n",
    "返回损失函数，参数梯度，最后一个隐藏层\n",
    "\"\"\"\n",
    "def lossFun(inputs, targets, prev_hidden):\n",
    "    \n",
    "    input_states, hidden_size, output_states = {}, {}, {}\n",
    "    #hidden_states[-1] = np.copy(prev_hidden)\n",
    "    hidden_states = []\n",
    "    hidden_states.append(np.copy(prev_hidden))\n",
    "    #hidden_states[-1] = np.copy(prev_hidden)\n",
    "    loss = 0\n",
    "    \n",
    "    # 第一部分：正向传播算法\n",
    "    for t in range(len(inputs)):\n",
    "        # 字符的独热码\n",
    "        input_states[t] = np.zeros((1,vocab_size))\n",
    "        input_states[t][0,inputs[t]] = 1\n",
    "        # 计算隐藏层的值\n",
    "        hidden_states[t] = np.tanh(np.dot(input_states[t], w_ih) + (np.dot(hidden_states[t-1],w_hh) + b_hh))\n",
    "        # 计算输出层加权值\n",
    "        logits = np.dot(hidden_states[t],w_ho) + b_ho\n",
    "        # 计算输出层的值\n",
    "        output_states[t] = np.exp(logits) / np.sum(np.exp(logits))\n",
    "        # 预测误差\n",
    "        loss += -np.log(output_states[t][0,targets[t]])\n",
    "        \n",
    "    # 第二部分：反向传播算法\n",
    "    grad_w_ih, grad_w_hh, grad_w_ho = np.zeros_like(w_ih), np.zeros_like(w_hh), np.zeros_like(w_ho)\n",
    "    grad_b_hh, grad_b_ho = np.zeros_like(b_hh), np.zeros_like(b_ho)\n",
    "    grad_hidden_next = np.zeros_like(hidden_states[0])\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        delta_output = np.copy(output_states[t])\n",
    "        delta_output[0,targets[t]] -= 1\n",
    "        grad_w_ho += np.dot(hidden_states[t].T, delta_output)\n",
    "        grad_b_ho += delta_output\n",
    "        grad_hidden = np.dot(delta_output, w_ho.T) + grad_hidden_next\n",
    "        delta_hidden = (1 - hidden_states[t]*hidden_states[t])*grad_hidden\n",
    "        \n",
    "        grad_b_hh += delta_hidden\n",
    "        grad_w_ih += np.dot(input_states[t].T, delta_hidden)\n",
    "        grad_w_hh += np.dot(hidden_states[t-1].T, delta_hidden)\n",
    "        grad_hidden_next = np.dot(delta_hidden, w_hh.T)\n",
    "        \n",
    "    for grad_param in [grad_w_ih, grad_w_hh, grad_w_ho, grad_b_hh, grad_b_ho]:\n",
    "        np.clip(grad_param, -2, 2, out=grad_param)\n",
    "        \n",
    "    return loss, grad_w_ih, grad_w_hh, grad_w_ho, grad_b_hh,grad_b_ho, hidden_states[len(inputs)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a48330e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数sample()，使用正向传播算法，通过随机抽样得到预测字符\n",
    "def sample(init_chars, n):\n",
    "    \"\"\"\n",
    "        从模型中随机抽样，得到一个正数序列\n",
    "        h是隐藏层状态\n",
    "    \"\"\"\n",
    "    hidden = np.zeros((1, hidden_size))\n",
    "    s = []\n",
    "    for t in range(len(init_chars) + n):\n",
    "        if t < (len(init_chars)):\n",
    "            ix = char_to_index[init_chars[t]]\n",
    "            input = np.zeros((1, vocab_size))\n",
    "            input[0, ix] = 1\n",
    "        else:\n",
    "            logits = np.dot(hidden, w_ho) + b_ho\n",
    "            prob = np.exp(logits) / np.sum(np.exp(logits))\n",
    "            ix = np.random.choice(range(vocab_size), p=prob.ravel())\n",
    "            input = np.zeros((1, vocab_size))\n",
    "            input[0,ix] = 1\n",
    "            \n",
    "        hidden = np.tanh(np.dot(input, w_ih) + (np.dot(hidden, w_hh) + b_hh))\n",
    "        s.append(ix)\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "# 超参数设置：隐藏层长度、输入序列长度、学习步长\n",
    "hidden_size, seq_length, lr = 20, 25, 0.1\n",
    "seq_num = int((len(data)-1)/seq_length)\n",
    "\n",
    "# 设置累计梯度初始值\n",
    "mem_w_ih, mem_w_hh, mem_w_ho = np.zeros_like(w_ih), np.zeros_like(w_hh), np.zeros_like(w_ho)\n",
    "mem_b_hh, mem_b_ho = np.zeros_like(b_hh), np.zeros_like(b_ho)\n",
    "\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length\n",
    "\n",
    "for e in range(epochs):\n",
    "    prev_hidden = np.zeros((1, hidden_size))\n",
    "    for i in range(seq_num):\n",
    "        # 准备输入数据、输出数据\n",
    "        seq_start, seq_end = i*seq_length, (i+1)*seq_length\n",
    "        inputs = [char_to_index[ch] for ch in data[seq_start:seq_end]]\n",
    "        targets = [char_to_index[ch] for ch in data[seq_start+1:seq_end+1]]\n",
    "        \n",
    "        # 调用函数lossFun，得到预测误差、参数梯度、隐藏层\n",
    "        loss, grad_w_ih, grad_w_hh, grad_w_ho, grad_b_hh, grad_b_ho, prev_hidden = lossFun(inputs, targets, prev_hidden)\n",
    "        smooth_loss = smooth_loss*0.999 + loss*0.001\n",
    "    \n",
    "        for paran, grad_param, mem in zip([w_ih, w_hh, w_ho, b_hh, b_ho],\\\n",
    "                                         [grad_w_ih, grad_w_hh, grad_w_ho, grad_b_hh, grad_b_ho],\\\n",
    "                                         [mem_w_ih, mem_w_hh, mem_w_ho, mem_b_hh, mem_b_ho]):\n",
    "            mem += np.abs(grad_param)\n",
    "            param -= lr * grad_param/np.sqrt(mem + le -8)\n",
    "        \n",
    "        # 随机抽样，得到预测误差\n",
    "        if (e % 5 == 0 or e == (epochs - 1)):\n",
    "            print('Epoch %d, loss: %f' % (e, smooth_loss))\n",
    "            sample_ix = sample(data[0:14],200)\n",
    "            s = ''.join(index_to_char[ix] for ix in sample_ix)\n",
    "            print('----\\n %s \\n----' % (s))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
